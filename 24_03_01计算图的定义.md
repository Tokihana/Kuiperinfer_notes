![image-20240301102057651](D:\College\projects\KuiperInfer_notes\24_03_01计算图的定义.assets\image-20240301102057651.png)



# PNNX计算图

KuiperInfer使用的模型格式为`PNNX`，是`Pytorch Neural Network Exchange`的缩写。这个格式是`NCNN`框架的一个pr中引入的，该格式希望能够将Pytorch模型导出为高效、简洁的计算图。详细可参考https://zhuanlan.zhihu.com/p/427620428

> PNNX是一套模型格式的定义和接口，优化点简单来说包括：
>
> 1. 将节点过多的子图优化为节点更少的子图
> 2. 将常量表达式替换为等价的常量，消除推理过程中未使用的常量
> 3. 合并重复计算的节点和表达式
>
> Kuiperinfer中需要做的是熟悉这个格式的结构定义，并对其再做一些封装。

回顾一下绪论中的内容，计算图主要包含以下部分：

1. `Operator`：计算图中的计算节点
2. `Graph`：多个Operator串联得到的有向无环图，规定了计算节点的执行顺序
3. `Layer`：Operator中具体执行运算的部分，首先读入输入Tensor中的数据，然后计算，将结果存放在输出Tensor中
4. `Tensor`：存放多维数据

PNNX计算图包括`Graph, Operator`和`Operand`三种结构。



## 测试模型

Kuiperinfer提供了一对小模型文件`linear.param`和`linear.bin`，分别为网络的结构和权重文件。网络的pytorch定义如下：

```py
class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.linear = nn.Linear(32, 128)
    def forward(self, x):
        x = self.linear(x)
        x = F.sigmoid(x)
        return x
```

可以使用Netron打开`linear.param`文件观察网络的结构

![image-20240301163151740](D:\College\projects\KuiperInfer_notes\24_03_01计算图的定义.assets\image-20240301163151740.png)

Linear层的结构，包含两个操作数`#0, #1`和两个权重属性`@weight, @bias`。

![image-20240301163157092](D:\College\projects\KuiperInfer_notes\24_03_01计算图的定义.assets\image-20240301163157092.png)



## Graph

`Graph`的功能是管理计算图中的`Operator`和`Operand`；其结构定义如下

```cpp
class Graph
{
    // 算子
    Operator* new_operator(const std::string& type, const std::string& name);
    Operator* new_operator_before(const std::string& type, const std::string& name, const Operator* cur);
    Operator* new_operator_after(const std::string& type, const std::string& name, const Operator* cur);
    
    // 操作数
    Operand* new_operand(const torch::jit::Value* v);
    Operand* new_operand(const std::string& name);
    Operand* get_operand(const std::string& name);
    
    std::vector<Operator*> ops;
    std::vector<Operand*> operands;
};
```



### 单元测试 - 输出算子

```cpp
TEST(test_ir, pnnx_graph_ops) {
  using namespace kuiper_infer;
  /**
   * 如果这里加载失败，请首先考虑相对路径的正确性问题
   */
  // LOG(INFO) << std::filesystem::current_path(); // 需要# include<filesystem>, 加这一行检查路径
  std::string bin_path("../../../src/model_file/test_linear.pnnx.bin"); // 这里要填远程主机上的模型相对路径
  std::string param_path("../../../src/model_file/test_linear.pnnx.param");
  std::unique_ptr<pnnx::Graph> graph = std::make_unique<pnnx::Graph>();
  int load_result = graph->load(param_path, bin_path);
  // 如果这里加载失败，请首先考虑相对路径(bin_path和param_path)的正确性问题
  ASSERT_EQ(load_result, 0);
  const auto &ops = graph->ops;
  for (int i = 0; i < ops.size(); ++i) {
    LOG(INFO) << ops.at(i)->name;
  }
}
```

> 如果出现模型路径加载失败的问题（open fail），请检查TEST中的模型路径，该路径应为远程主机中模型文件和build的之间的相对路径。

```cpp
I20240301 08:55:21.320151  1057 test_ir.cpp:37] pnnx_input_0
I20240301 08:55:21.320165  1057 test_ir.cpp:37] linear
I20240301 08:55:21.320171  1057 test_ir.cpp:37] F.sigmoid_0
I20240301 08:55:21.320178  1057 test_ir.cpp:37] pnnx_output_0
```

可以看到，`Graph`中存在四个算子：`input_0, linear, sigmoid_0, output_0`。

### 单元测试 - 输出操作数

```cpp
TEST(test_ir, pnnx_graph_operands) {
  using namespace kuiper_infer;
  /**
   * 如果这里加载失败，请首先考虑相对路径的正确性问题
   */
  std::string bin_path("../../../src/model_file/test_linear.pnnx.bin");
  std::string param_path("../../../src/model_file/test_linear.pnnx.param");
  std::unique_ptr<pnnx::Graph> graph = std::make_unique<pnnx::Graph>();
  int load_result = graph->load(param_path, bin_path);
  // 如果这里加载失败，请首先考虑相对路径(bin_path和param_path)的正确性问题
  ASSERT_EQ(load_result, 0);
  const auto &ops = graph->ops;
  for (int i = 0; i < ops.size(); ++i) {
    const auto &op = ops.at(i);
    LOG(INFO) << "OP Name: " << op->name;
    LOG(INFO) << "OP Inputs";
    for (int j = 0; j < op->inputs.size(); ++j) {
      LOG(INFO) << "Input name: " << op->inputs.at(j)->name
                << " shape: " << ShapeStr(op->inputs.at(j)->shape);
    }

    LOG(INFO) << "OP Output";
    for (int j = 0; j < op->outputs.size(); ++j) {
      LOG(INFO) << "Output name: " << op->outputs.at(j)->name
                << " shape: " << ShapeStr(op->outputs.at(j)->shape);
    }
    LOG(INFO) << "---------------------------------------------";
  }
}
```

```cpp
I20240301 08:55:21.320255  1057 test_ir.cpp:56] OP Name: pnnx_input_0
I20240301 08:55:21.320262  1057 test_ir.cpp:57] OP Inputs
I20240301 08:55:21.320267  1057 test_ir.cpp:63] OP Output
I20240301 08:55:21.320274  1057 test_ir.cpp:65] Output name: 0 shape: 1 x 32
I20240301 08:55:21.320281  1057 test_ir.cpp:68] ---------------------------------------------
I20240301 08:55:21.320287  1057 test_ir.cpp:56] OP Name: linear
I20240301 08:55:21.320292  1057 test_ir.cpp:57] OP Inputs
I20240301 08:55:21.320298  1057 test_ir.cpp:59] Input name: 0 shape: 1 x 32
I20240301 08:55:21.320305  1057 test_ir.cpp:63] OP Output
I20240301 08:55:21.320362  1057 test_ir.cpp:65] Output name: 1 shape: 1 x 128
I20240301 08:55:21.320374  1057 test_ir.cpp:68] ---------------------------------------------
I20240301 08:55:21.320380  1057 test_ir.cpp:56] OP Name: F.sigmoid_0
I20240301 08:55:21.320386  1057 test_ir.cpp:57] OP Inputs
I20240301 08:55:21.320392  1057 test_ir.cpp:59] Input name: 1 shape: 1 x 128
I20240301 08:55:21.320405  1057 test_ir.cpp:63] OP Output
I20240301 08:55:21.320420  1057 test_ir.cpp:65] Output name: 2 shape: 1 x 128
I20240301 08:55:21.320432  1057 test_ir.cpp:68] ---------------------------------------------
I20240301 08:55:21.320443  1057 test_ir.cpp:56] OP Name: pnnx_output_0
I20240301 08:55:21.320453  1057 test_ir.cpp:57] OP Inputs
I20240301 08:55:21.320461  1057 test_ir.cpp:59] Input name: 2 shape: 1 x 128
I20240301 08:55:21.320467  1057 test_ir.cpp:63] OP Output
I20240301 08:55:21.320478  1057 test_ir.cpp:68] ---------------------------------------------
```

